### Machine Learning Portfolio - Sara Shahin


This Portfolio is a compilation of all the Machine Learning and Deep Learning projects I have done for academic, self-learning and hobby purposes. This portfolio also contains my Achievements, skills, and certificates. It is updated on the regular basis.

   Email: sara.shahin2007@gmail.com
  
   LinkedIn: https://www.linkedin.com/in/sara-shahin-3a842929/
   
   
  ### Achievements
  Recipient of First-Class Honours Bachelor Degree of Computer Science - Machine Learning & Artificial Intelligence.
  
  Awarded a Scholarship Data Science Course Bertelsmann Education Group
  
  ## Projects
  
   <img align="left" src="https://github.com/sarashahin/MyOfficialPortfolio/blob/main/images/Screenshot%202023-02-13%20at%2020.20.51.png" alt="My Image">
   
  [Multimodal-Fake-News-Detection](https://github.com/sarashahin/Multimodal-Fake-News-Detection)
  
  I examined different deep learning architectures for text classification such as Bidirectional long short-term memory (BiLSTM) and Bidirectional encoder   representations from transformers (BERT). As a multimodal approach, I proposed a CNN architecture that combines both texts and images to classify the       fake news.
  
   ## <img align="left" src="https://github.com/sarashahin/MyOfficialPortfolio/blob/main/images/download.jpeg" alt="My Image" height='150' width = '130'> 
    
 [RSNA Screening Mammography Breast Cancer Detection](https://www.kaggle.com/code/sarashahin/rsna-screening-mammography-breast-cancer-detection)
    
 The goal of this competition is to identify breast cancer using logistic regression model.
    
 <br>
  
   ## <img align="left" src="https://github.com/sarashahin/MyOfficialPortfolio/blob/main/images/1_rnko_Sy3iEQ-sUbzmU4A-A.png" alt="My Image" height='150'       width = '130'>

[text-classification](https://github.com/sarashahin/Textclassification/blob/main/text-classification.ipynb)
  
  
Trained a Logistic Regression and Recurrent Neural Network (with LSTM layer) methods to carry out classification of Ironic and Sarcastic Tweets using      Natural Language Processing. Pre-processing of the text data and word vectorisation was required before training these methods using TensorFlow.            Evaluate the methods' performance based on Precision, Recall, and F-Scores.


  ## <img align="left" src="https://github.com/sarashahin/MyOfficialPortfolio/blob/main/images/images.jpeg" alt="My Image" height='150' width = '130'>

[Diabetes_Retinopathy_Dectetion_UNet_augment](https://github.com/sarashahin/DiabetesRetinopathyDectetion_UNet_augment./blob/main/DiabetesRetinopathyDectetion_UNet_augment.ipynb)

The unet_model function defines the architecture of the U-Net model using a series of convolutional, pooling, and transpose convolutional layers. The model takes an input tensor of shape input_shape and returns an output tensor of shape (height, width, 1).


   ## <img align="left" src="https://github.com/sarashahin/MyOfficialPortfolio/blob/main/images/Screenshot%202023-03-27%20at%2021.20.46.png" alt="My Image"    height='150' width = '130'>
   
[Google - Isolated Sign Language Recognition]
(https://www.kaggle.com/code/sarashahin/isolatedsignlanguagerecognition)

# Still working on it

The goal of this competition is to classify isolated American Sign Language (ASL) signs. Create a TensorFlow Lite model trained on labeled landmark data
<br>


# Micro Projects

   ***Statistics and Machine Learning***

   > [Neural Network Word Embedding](https://github.com/sarashahin/word_Embedding/blob/main/word-embedding.ipynb):
Learn word embeddings jointly with the main task that care about (e.g. document classification or sentiment prediction). In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network. Load into your model word embeddings that were pre-computed using a different machine learning task than the one you are trying to solve. These are called pre-trained word embeddings.

> [Analysis Data](https://github.com/sarashahin/Dealing-with-data/blob/master/Dealingwithdata.ipynb):
Data Processing, Data Cleaning, Exploratory Analysis and Data Visualization

> [Pre-trained Inception V3 model Deepdream-keras](https://github.com/sarashahin/deepDream_keras/blob/main/deepdream-keras.ipynb):
This code loads a pre-trained Inception V3 model, defines a function to read and preprocess an image, downsizes the image to make it easier to work with, and defines a function to calculate the loss for a given image and model. It also defines some utility functions to deprocess and display an image. It creates a feature extraction model using the specified layers of the loaded model. Uses gradient ascent to update the input image iteratively.

### Challenges
> Data Science Challenges: This repository contains codes of online Data Science challenges (From Hackerrank, etc.) solved by me.

> Kaggle Competition RSNA Screening Mammography Breast Cancer Detection https://www.kaggle.com/sarashahin/competitions

## Core Competencies

**Methodologies** : Machine Learning, Deep Learning, Natural Language Processing, Statistics and Data Analytics

**Languages**: Python (Pandas, Numpy, Scikit-Learn, Scipy, Keras, TensorFlow, Matplotlib), SQL, C++, JavaScript

**Tools**: MySQL, Tableau, Git, HTML, CSS, MS Excel

## Certificates
 * [Deep Learning by Stanford University Online(Coursera)](https://coursera.org/share/57c4f47585f24a15b0f7c7f9675352f3)
 * [Machine Learning by Stanford University Online(Coursera)](https://coursera.org/share/8de9508deb43955e79ab4cbe4e96d138)
 * [IBM Data Science](https://coursera.org/share/81c4e2ae2b5576dc5f08a55357fcbda0)
 * [IBM AI Engineering](https://coursera.org/share/ada7c46619bfec173e3d3e2490063320)
 * [Google IT Support](https://coursera.org/share/70636438ee231b5da6a3d9eb51ffcb5d)
